{
    "summary": "The code features a `download_external` function, utilizing lazero network downloader for efficient file downloads, multithreading, error handling, progress updates with tqdm, and race condition prevention.",
    "details": [
        {
            "comment": "This code defines a function to convert file size units, retrieve the file size using different units (KB, MB, GB), and uses pycurl library to probe the file size from a URL.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":0-47",
            "content": "# from argparse import ArgumentParser\nimport requests\nimport enum\nimport os\nfrom tqdm import tqdm\nclass sizeUnit(enum.Enum):\n    # class to store the various units\n    BYTES = 1\n    KB = 2\n    MB = 3\n    GB = 4\ndef unitConvertor(sizeInBytes, unit):\n    # Cinverts the file unit\n    if unit == sizeUnit.KB:\n        return sizeInBytes / 1024\n    elif unit == sizeUnit.MB:\n        return sizeInBytes / (1024 * 1024)\n    elif unit == sizeUnit.GB:\n        return sizeInBytes / (1024 * 1024 * 1024)\n    else:\n        return sizeInBytes\ndef fileSize(filePath, size_type):\n    \"\"\"File size in KB, MB and GB\"\"\"\n    size = os.path.getsize(filePath)\n    return unitConvertor(size, size_type)\ndef pyCURLFileSizeProbe(url):\n    from io import StringIO\n    STATUS_OK = (200, 203, 206)\n    STATUS_ERROR = range(400, 600)\n    import pycurl\n    ss = StringIO()\n    curl = pycurl.Curl()\n    curl.setopt(pycurl.FOLLOWLOCATION, 1)\n    curl.setopt(pycurl.MAXREDIRS, 5)\n    curl.setopt(pycurl.CONNECTTIMEOUT, 30)\n    curl.setopt(pycurl.TIMEOUT, 300)\n    curl.setopt(pycurl.NOSIGNAL, 1)"
        },
        {
            "comment": "The code is using the pycurl library to download a file from a URL. It sets options for the download, performs the download, checks for errors or successful response, and returns the size of the downloaded content.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":48-83",
            "content": "    curl.setopt(pycurl.NOPROGRESS, 1)\n    curl.setopt(pycurl.NOBODY, 1)\n    curl.setopt(pycurl.HEADERFUNCTION, ss.write)\n    curl.setopt(pycurl.URL, url)\n    try:\n        curl.perform()\n    except:\n        pass\n    size = None\n    if curl.errstr() == \"\" and curl.getinfo(pycurl.RESPONSE_CODE) in STATUS_OK:\n        # url_info['url'] = curl.getinfo(pycurl.EFFECTIVE_URL)\n        # url_info['file'] = os.path.split(url_info['url'])[1]\n        size = int(curl.getinfo(pycurl.CONTENT_LENGTH_DOWNLOAD))\n    else:\n        try:\n            size = int(curl.getinfo(pycurl.CONTENT_LENGTH_DOWNLOAD))\n        except:\n            pass\n        print(\"PYCURL ERROR:\", curl.errstr())\n        try:\n            print(\"RESPONSE CODE:\", curl.getinfo(pycurl.RESPONSE_CODE))\n        except:\n            print(\"FAILED TO GET RESPONSE CODE\")\n    curl.close()\n    return size\ndef pyCURLDownload(url, download_path, timeout: int = 120):\n    import pycurl\n    file_name = download_path\n    file_src = url\n    with open(file_name, \"wb\") as f:\n        cl = pycurl.Curl()"
        },
        {
            "comment": "This code defines a function `download_external` that uses the PyCurl library to download a file from a given URL and save it with a specified filename. The function also takes additional configuration options such as allowing redirects, showing progress, using multithreading, setting thread counts, and timeouts.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":84-119",
            "content": "        cl.setopt(pycurl.URL, file_src)\n        cl.setopt(pycurl.WRITEDATA, f)\n        cl.setopt(pycurl.TIMEOUT, timeout)\n        cl.perform()\n        cl.close()\n# from retry import retry\n# @retry(tries=2)\ndef download_external():\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--url\", type=str, required=True, help=\"URL to download\")\n    parser.add_argument(\n        \"--filename\", type=str, required=True, help=\"filename to write content to\"\n    )\n    parser.add_argument(\"--config\", type=str, default=\"{}\", help=\"config json string\")\n    args = parser.parse_args()\n    import json\n    config_input = json.loads(args.config)\n    assert type(config_input) == dict\n    config = {\n        \"allow_redirects\": True,\n        \"show_progress\": True,\n        \"use_multithread\": True,\n        \"threads\": 6,\n        \"max_threads\": 100,\n        \"min_threads\": 4,\n        \"redownload\": False,\n        \"timeout\": 30,  # will that work?\n        \"size_filter\": {},  # in megabytes?\n        \"skip_verification\": True,"
        },
        {
            "comment": "Function for downloading a file with various options, including the ability to use an external downloader if specified.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":120-155",
            "content": "    }\n    config.update(config_input)\n    config.update({\"external\": False})\n    download(args.url, args.filename, **config)\ndef download(\n    url,\n    filename,\n    allow_redirects=True,\n    show_progress=True,\n    use_multithread=True,\n    threads: float = 6,\n    use_proxy: bool = False,\n    max_threads=100,\n    min_threads=4,\n    redownload=False,\n    timeout=30,  # will that work?\n    size_filter: dict = {},  # in megabytes?\n    skip_verification: bool = True,\n    external: bool = True,  # set it to True in our damn project.\n):\n    if external:\n        print(\"using external downloader\")\n        import subprocess\n        commandArgs = {\n            \"allow_redirects\": allow_redirects,\n            \"show_progress\": show_progress,\n            \"use_multithread\": use_multithread,\n            \"threads\": threads,\n            \"max_threads\": max_threads,\n            \"min_threads\": min_threads,\n            \"redownload\": redownload,\n            \"timeout\": timeout,  # will that work?\n            \"size_filter\": size_filter,  # in megabytes?"
        },
        {
            "comment": "This code is running a subprocess to download a file using the lazero network downloader. It passes arguments such as URL, filename, and command options in a JSON-formatted string. If skip_verification is True, it skips SSL verification during the download process. If use_proxy is False, it clears the http and https proxies from the environment variables. It also applies a min size filter if provided.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":156-190",
            "content": "            \"skip_verification\": skip_verification,\n            \"external\": False,\n        }\n        import json\n        commandArgs = json.dumps(commandArgs)\n        try:\n            result = subprocess.run(\n                [\n                    \"python3\",\n                    \"-m\",\n                    \"lazero.network.downloader\",\n                    \"--url\",\n                    url,\n                    \"--filename\",\n                    filename,\n                    \"--config\",\n                    commandArgs,\n                ],\n                shell=False,\n                timeout=timeout,\n            )\n            return result.returncode == 0 and os.path.exists(\n                filename\n            )  # check if this succeeds\n        except:\n            print(\"downloader timeout\")\n            return False\n    if skip_verification:\n        import requests_skip_verify\n        requests_skip_verify.set(True)\n    if not use_proxy:\n        os.environ[\"http_proxy\"] = \"\"\n        os.environ[\"https_proxy\"] = \"\"\n    min_size_filter = size_filter.get(\"min\", None)"
        },
        {
            "comment": "This code checks the file size without actually downloading the file. It gets the maximum and minimum size filters from a dictionary, then attempts to get the total content length of the URL using requests module. If redownload is not set and the file already exists, it compares its size with the total content length if it's available. If there's no server response (total is None), and either min_size or max_size filters are present, it prints a message indicating that it can't filter the file size without server response.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":191-224",
            "content": "    max_size_filter = size_filter.get(\"max\", None)\n    use_requests = True\n    # try:\n    with requests.get(\n        url,\n        stream=True,\n        allow_redirects=allow_redirects,\n        timeout=timeout,\n        verify=skip_verification,\n    ) as response:\n        total = response.headers.get(\"content-length\")\n        # except:\n        #     use_requests = False\n        # import traceback\n        # traceback.print_exc()\n        # print(\"unknown requests error. might be open files limit\")\n        # total = pyCURLFileSizeProbe(url)\n        if not redownload:\n            if os.path.exists(filename):\n                if total:\n                    filesize = os.path.getsize(filename)\n                    if filesize == total:\n                        return True\n                else:\n                    return True\n        basename = os.path.basename(filename)\n        one_megabyte = 1024**2\n        if total is None:\n            if min_size_filter or max_size_filter:\n                print(\n                    \"Not downloading since don't know how to filter file size without server response\""
        },
        {
            "comment": "Checks if file size meets min or max size filter before downloading.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":225-248",
            "content": "                )\n                return False\n        else:\n            total = int(total)\n            size = unitConvertor(total, sizeUnit.MB)\n            size = float(size)\n            if min_size_filter:\n                if size < min_size_filter:\n                    print(\"Min size filter is %.5f MB\" % min_size_filter)\n                    print(\"File Size is %.5f MB\" % size)\n                    print(\"Not downloading since filtered by min size filter\")\n                    return False\n            if max_size_filter:\n                if size > max_size_filter:\n                    print(\"Max size filter is %.5f MB\" % max_size_filter)\n                    print(\"File Size is %.5f MB\" % size)\n                    print(\"Not downloading since filtered by max size filter\")\n                    return False\n        try:\n            # main download section.\n            if total is None:\n                if use_requests:\n                    with open(filename, \"wb\") as f:\n                        print(\"Downloading %s\" % filename)"
        },
        {
            "comment": "This code segment handles the process of downloading files. If the file is already present in the desired location, it calls a function to resume the download. Otherwise, it prints progress information and sets up thread management for the download process. The threads are dynamically adjusted based on the file size and other settings.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":249-270",
            "content": "                        f.write(response.content)\n                else:\n                    pyCURLDownload(url, filename, timeout=timeout)\n            else:\n                print(\"Downloading %s of size %.5f MB\" % (basename, size))\n                print(\"Saving at %s\" % filename)\n                if use_multithread:\n                    if threads == 0:\n                        threads = 6\n                    if threads < 0:\n                        # print(\"TOTAL\", total)\n                        # print(\"ONE_MEGABYTE\", one_megabyte)\n                        # print(\"-THREADS\", -threads)\n                        a = one_megabyte * (-threads)\n                        # print(\"ONE_MEGABYTE*(-THREADS)\", a)\n                        b = total / a\n                        # print(\"TOTAL/A\",b)\n                        c = round(b)\n                        # print(\"ROUND(B)\", c)\n                        threads = c\n                    threads = int(threads)\n                    threads = min(max_threads, max(min_threads, threads))"
        },
        {
            "comment": "Scheduling a 0.1 second delay before and after starting the downloader thread.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":271-295",
            "content": "                    print(\"using %d threads\" % threads)\n                    import multithread\n                    download_object = multithread.Downloader(\n                        url,\n                        filename,\n                        progress_bar=show_progress,\n                        threads=threads,\n                        aiohttp_args={\n                            \"method\": \"GET\",\n                            \"allow_redirects\": allow_redirects,\n                            \"timeout\": timeout,\n                            \"verify_ssl\": skip_verification,\n                            \"ssl\": skip_verification if not skip_verification else None,\n                        },\n                    )\n                    try:\n                        import time\n                        time.sleep(0.1)  # wtf?\n                        download_object.start()\n                        time.sleep(0.1)  # wtf?\n                        # it might have issue.\n                    except:\n                        import traceback"
        },
        {
            "comment": "Handles multithread downloads, falling back to asyncio and pyCURLDownload if an error occurs.\nUses requests or pyCURLDownload based on config settings.\nDisplays progress using tqdm if show_progress is True.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":297-317",
            "content": "                        traceback.print_exc()\n                        print(\"error when using multithread download\")\n                        import asyncio\n                        asyncio.set_event_loop(asyncio.new_event_loop())\n                        pyCURLDownload(url, filename, timeout=timeout)\n                else:\n                    if use_requests:\n                        with open(filename, \"wb\") as f:\n                            if show_progress:\n                                for data in tqdm(\n                                    response.iter_content(\n                                        chunk_size=max(int(total / 1000), 1024 * 1024)\n                                    )\n                                ):\n                                    f.write(data)\n                            else:\n                                f.write(response.content)\n                    else:\n                        pyCURLDownload(url, filename)\n                print(\"Finished downloading %s of size %.2f MB\" % (basename, size))"
        },
        {
            "comment": "Trying to download a file and printing success or failure message.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/network/downloader.py\":318-330",
            "content": "                print(\"Saved at %s\" % filename)\n            return True\n        except:\n            import traceback\n            traceback.print_exc()\n            print(\"Failed to download file %s\" % filename)\n            print(\"File URL: %s\" % url)\n            return False\nif __name__ == \"__main__\":\n    download_external()"
        }
    ]
}