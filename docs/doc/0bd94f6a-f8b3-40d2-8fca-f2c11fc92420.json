{
    "summary": "This code uses Whoosh library in Python to perform searches, considering index directory and search fields. It allows optional filtering by file path and adjusts epsilon value for hit scores. The function balances search fields using weight parameter and retrieves relevant information for each query version.",
    "details": [
        {
            "comment": "The code imports necessary modules, defines a function for indexing search in Whoosh, and another for performing a single search query. It uses LRU cache for performance optimization and ensures the index directory exists before proceeding with the search.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/search/whoosh/search.py\":0-30",
            "content": "# from lazero.search.whoosh.model import analyzer\n# we do highligh in another way.\nfrom whoosh.index import open_dir\nfrom whoosh import qparser\nfrom whoosh.query import Term\nfrom lazero.search.preprocessing import getFourVersionsOfProcessedLine\nfrom functools import lru_cache\n@lru_cache(maxsize=1)\ndef whooshSearchBootstrap(\n    indexDirectory,\n    search_fields:tuple=(\"path_m1\", \"path_m2\", \"path_m3\", \"path_m4\", \"content\"),\n    indexname=\"article_index\",\n):\n    search_fields = list(search_fields)\n    assert os.path.exists(indexDirectory)\n    assert os.path.isabs(indexDirectory)\n    ix = open_dir(indexDirectory, indexname=indexname)\n    schema = ix.schema\n    og = qparser.OrGroup.factory(0.9)\n    mp = qparser.MultifieldParser(search_fields, schema, group=og)\n    print(\"Loaded whooshSearchBootstrap index directory: \" + indexDirectory)\n    return ix, schema, og, mp\ndef whooshSearchSingle(\n    search_query_processed,\n    indexDirectory,\n    search_fields:tuple=(\"path_m1\", \"path_m2\", \"path_m3\", \"path_m4\", \"content\"),"
        },
        {
            "comment": "This code is initializing a Whoosh search index and performing a search query. It takes an index directory, search fields, index name, and optional filter filepath as input. It then parses the search query, searches for matches using terms and optionally filters by file path, and returns the results. The code also adjusts a character limit for fragments and iterates over the search results, possibly ignoring the content field in favor of original content.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/search/whoosh/search.py\":31-56",
            "content": "    indexname=\"article_index\",\n    epsilon=1e-3,\n    limit=100,\n    weight=0.7,\n    filter_filepath=None,  # to search for specific file only.\n):  # remember that 'path' is not 'multiplexed'\n    # ix, schema, og, mp = whooshSearchBootstrap(indexDirectory, search_fields=search_fields,indexname=indexname)\n    # maybe they don't need some.\n    ix, _, _, mp = whooshSearchBootstrap(\n        indexDirectory, search_fields=search_fields, indexname=indexname\n    )\n    q = mp.parse(search_query_processed)\n    with ix.searcher() as s:\n        if filter_filepath:\n            allow_q = Term(\"path\", filter_filepath)\n            results = s.search(q, terms=True, limit=limit, filter=allow_q)\n        else:\n            results = s.search(q, terms=True, limit=limit)  # what fucking terms?\n        # we don't need this stuff no more.\n        # cause your index is bloated.\n        # results.fragmenter.charlimit = 100000\n        lastScore = 2\n        maxScore = 0\n        for hitIndex, hit in enumerate(results):\n            # content = hit[\"content\"] # the content is not important. we need original content, not these fake shits."
        },
        {
            "comment": "This code performs a search using the Whoosh library in Python. It takes a query, an index directory, and a list of search fields as input parameters. The code iterates over search hits, calculates normalized scores based on hit scores, and yields the index and normalized score. Additionally, it allows for optional filtering by file path and adjusts the hit score if it's below a certain epsilon value to prevent assigning '100% certain' status. The code also uses a weight parameter to balance different search fields and an option to include original line information from the tinydb database.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/search/whoosh/search.py\":57-85",
            "content": "            score = hit.score\n            if score < epsilon:\n                score = lastScore / 2\n            if hitIndex == 0:\n                maxScore = score\n            lastScore = score\n            normalized_score = (score / maxScore) * weight\n            index = hit[\"index\"]\n            yield index, normalized_score\n            # path = hit['path']\n            # we need some unified interface to process this shit.\n# from lazero.search.whoosh.api import getValueByKeyFromDatabase\nimport os\nfrom lazero.search.api import lazeroCachePath\nfrom lazero.search.search import updateDataDictWithLineIndexNormalizedScoreAndDivisor\ndef whooshSearch(\n    query,\n    indexDirectory,\n    search_fields:tuple=(\"path_m1\", \"path_m2\", \"path_m3\", \"path_m4\", \"content\"),\n    indexname=\"article_index\",\n    epsilon=1e-3,\n    limit=100,\n    filter_filepath=None,\n    weight=0.7,  # do not mark our top hit as '100% certain'\n    withOriginalLine=True,  # this is default behavior of indexer. you still need to retrieve this flag from tinydb."
        },
        {
            "comment": "This function performs a search query using Whoosh and retrieves the results, then updates a dictionary with line index, normalized score, and divisor for each version of the processed query.",
            "location": "\"/media/root/Toshiba XG3/works/lazero/docs/src/lazero/search/whoosh/search.py\":86-113",
            "content": "    tinydbDatabasePath=os.path.join(lazeroCachePath, \"index.json\"),\n    dataDict={},  # for using with txtai\n):  # will multiplex the thing.\n    divisor = 4 + int(withOriginalLine)\n    fourProcessedLines = list(getFourVersionsOfProcessedLine(query))\n    for search_query_processed in (\n        [query] if withOriginalLine else []\n    ) + fourProcessedLines:\n        for index, normalized_score in whooshSearchSingle(\n            search_query_processed,\n            indexDirectory,\n            search_fields=search_fields,\n            indexname=indexname,\n            limit=limit,\n            weight=weight,\n            epsilon=epsilon,\n            filter_filepath=filter_filepath,\n        ):\n            dataDict = updateDataDictWithLineIndexNormalizedScoreAndDivisor(\n                dataDict,\n                index,\n                normalized_score,\n                divisor,\n                tinydbDatabasePath=tinydbDatabasePath,\n            )\n    # you decide what to do with dataDict later.\n    return dataDict"
        }
    ]
}